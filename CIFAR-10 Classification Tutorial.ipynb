{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CIFAR-10 dataset is one of the most commonly used datasets for deep learning and image classification, popular becasue of its versatility and ease of use. This notebook will walk you through the process of running an image classifciation algorithm on the CIFAR-10 dataset using PyTorch. It will also go through the ideas behind deep learning image classification, acting as a practical tutorial to image classification with PyTorch. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin with, we'll need to start by importing all the necessary modules and libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch has a convenient and simple way of passing image data into the deep neural network model - the DataLoader. When we use the DataLoader, we first have to set up the dataset we want the loader to pass to the model. CIFAR-10 is so common that PyTorch has the dataset prepackaged in it, but we also need to specify certain transforms that the dataset will use. Transforms are arguments we pass to the dataset function that control how the dataset is handled when it is loaded. The most important transform is `ToTensor`, as this makes the images a tensor that the model can interpret, but it is also important to normalize the image data, as the pixels have different values and when unnormalized they can cause the image classifier to learn the wrong patterns. \n",
    "\n",
    "You may also want to engage in some data augmentation, and add extra arguments to the transforms for the traning set These transforms are different perturbations, like warping and shifting of the images, that can improve the classifier's robustness and make it able to recognize objects under more circumstances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transforms to use\n",
    "# creates a tensor with all values divided in half to normalize\n",
    "\n",
    "train_transforms = transforms.Compose(\n",
    "    [transforms.RandomRotation(30),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# Create training and testing datasets\n",
    "train_data = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=train_transforms)\n",
    "# loader creates an iterable object for later use\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=4,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=test_transforms)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=4,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to specify the number of classes here, as the number of classes should be the output number for the final layer of the moel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go about setting up the model. In PyTorch, we can create a custom network model by inheriting from `nn.Module` and then specifying the layers we want to use. We declare the individual layers we want to use in the class construction and then define a forward pass function to carry out the training. We'll need the convolutional layers, the Max Pooling layers, and the Linear layers.\n",
    "\n",
    "As for the activation functions and the flattening of the tensor, that can be carried out with the `Functional` module from PyTorch (letting you use the functions as is), and with the `view` function, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # the functional nn allows you to get more explicit than nn.sequential\n",
    "        # which means you have to manually define the parameters\n",
    "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, num_classes)\n",
    "\n",
    "    # Define the forward pass, overwrite X for different layers\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # .view behaves like -1 in numpy.reshape(), i.e. the actual value for this dimension will\n",
    "        # be inferred so that the number of elements in the view matches the original number of elements.\n",
    "        x = x.view(-1, 128 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to instantiate the custom classifier by making an instance of it as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the class model\n",
    "\n",
    "model = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to define the loss function and the optimizer that we want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function and optimizer\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now go about defining the training loop for the model.  We'll specify a number of epochs to train for and then get the training instances from the trainloader. We can then get the inputs and send them through the model, saving the outputs of the model as a variable. After this, we'll use the outputs and get the loss by comparing the outputs and the ground truth labels with our specified criterion. After the loss has been calculated, we can do backpropogation and then carry out optimization using the optimizer. We'll also print out some statistics at the end of every epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the network\n",
    "\n",
    "for epoch in range(65):\n",
    "\n",
    "    running_loss = 0.0\n",
    "\n",
    "    # for every instance/example in the train_loader, get data and index\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # be sure to zero the gradients for every new epoch\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Instantiate forward + backward + optimize\n",
    "        # define the outputs as a function of the net on inputs\n",
    "        outputs = model(inputs)\n",
    "        # set the loss as difference between labels and outputs with chosen criterion\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Carry out backprop\n",
    "        loss.backward()\n",
    "        # Optimize\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to evaluate the performance of the trained classifier. We'll use the test dataloader to get the images and the correct labels. We don't have to show the images to check the performance of the classifier, but it may prove useful. We need to convert the images back to their previous un-normalized state if we are going to show them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the test_loader to get images and labels for the test set\n",
    "\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = data_iter.next()\n",
    "\n",
    "def imshow(img):\n",
    "    # because we normalized the data, we need to put it back to its original state\n",
    "    img = img / 2 + 0.5\n",
    "    # create a numpy array out of the image\n",
    "    img = img.numpy()\n",
    "    # transpose image to format - (height, width, color)\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# define all the classes we have in the dataset\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "# print output\n",
    "print('Actual: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
    "\n",
    "# need to make the outputs just the images run through the network\n",
    "outputs = model(images)\n",
    "\n",
    "# getting the most likely class for the prediction\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to see how the network performs against the testing data. First, we set the torch setting to \"no_grad\", so the gradients aren't updated as we test the network. Then for all the data in the dataloader, we need to get the images and labels. We can then run the images through the model and get the predictions, just like before. This time though, we compare the predicted data to the label, and if the values are the same we count it as being correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see how the network as a whole performs\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "#  \"with torch.no_grad()\" temporarily sets all the requires_grad flag to false\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        # total is the size of labels, every label\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Model accuracy on test data: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
